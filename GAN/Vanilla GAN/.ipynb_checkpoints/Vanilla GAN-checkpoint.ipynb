{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = 3.0\n",
    "data_std = 0.4\n",
    "\n",
    "Series_Length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_input_size = 20    \n",
    "g_hidden_size = 150  \n",
    "g_output_size = Series_Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_input_size = Series_Length    \n",
    "d_hidden_size = 75  \n",
    "d_output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more batches to discriminator to learn faster than generator\n",
    "d_minibatch_size = 1500\n",
    "g_minibatch_size = 1000\n",
    "\n",
    "num_epochs = 10000\n",
    "print_interval = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_learning_rate = 3e-3\n",
    "g_learning_rate = 8e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_sampler(mu, sigma):\n",
    "    dist = Normal(mu, sigma)\n",
    "    return lambda m, n: dist.sample((m,n)).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_sampler():\n",
    "    return lambda m, n: torch.rand(m,n).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_data = get_real_sampler(data_mean, data_std)\n",
    "noise_data = get_noise_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.xfer = torch.nn.SELU()\n",
    "    def forward(self, x):\n",
    "        x = self.xfer(self.map1(x))\n",
    "        x = self.xfer(self.map2(x))\n",
    "        return self.xfer(self.map3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.elu = torch.nn.ELU()\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.map1(x))\n",
    "        x = self.elu(self.map2(x))\n",
    "        return torch.sigmoid(self.map3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.SGD(D.parameters(), lr = d_learning_rate)\n",
    "g_optimizer = optim.SGD(G.parameters(), lr = g_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_D_on_actual():\n",
    "    real_data = actual_data(d_minibatch_size, d_input_size)\n",
    "    real_data = Variable(real_data, requires_grad=False)\n",
    "    real_decision = D(real_data)\n",
    "    real_error = criterion(real_decision, torch.ones(d_minibatch_size, 1))\n",
    "    real_error.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_D_on_generated():\n",
    "    noise = noise_data(d_minibatch_size, g_input_size)\n",
    "    noise = Variable(noise, requires_grad=False)\n",
    "    fake_data = G(noise)\n",
    "    fake_decision = D(fake_data)\n",
    "    fake_error = criterion(fake_decision, torch.zeros(d_minibatch_size,1))\n",
    "    fake_error.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_G():\n",
    "    noise = noise_data(g_minibatch_size, g_input_size)\n",
    "    noise = Variable(noise, requires_grad=False)\n",
    "    fake_data = G(noise)\n",
    "    fake_decision = D(fake_data)\n",
    "    error = criterion(fake_decision, torch.ones(g_minibatch_size, 1))\n",
    "    error.backward()\n",
    "    return error.item(), fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw( data ) :    \n",
    "    plt.figure()\n",
    "    d = data.tolist() if isinstance(data, torch.Tensor) else data\n",
    "    plt.plot( d ) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    D.zero_grad()\n",
    "    \n",
    "    train_D_on_actual()\n",
    "    train_D_on_generated()\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    G.zero_grad()\n",
    "    loss,generated = train_G()\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    losses.append(loss)\n",
    "    if (epoch % print_interval) == (print_interval-1):\n",
    "        print(\"Epoch %6d. Loss %5.3f\" % ( epoch+1, loss ))\n",
    "        draw( torch.histc( generated, min=0, max=5, bins=53 ).t() )\n",
    "        \n",
    "print(\"training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = torch.empty(generated.size(0), 53) \n",
    "for i in range( 0, d.size(0) ) :\n",
    "    d[i] = torch.histc(generated[i], min=0, max=5, bins=53)\n",
    "draw( d.t() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
